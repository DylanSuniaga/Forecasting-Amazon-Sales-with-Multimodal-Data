{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25618c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('./../../data/all_keywords_merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8754d0f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['keyword', 'source_file', 'asin', 'item_name', 'brand', 'image_count',\n",
       "       'main_image_url', 'has_aplus', 'has_brand_story', 'review_count',\n",
       "       'avg_rating', 'bsr_best', 'bsr_paths', 'units_per_month',\n",
       "       'sales_velocity_daily', 'product_url', 'image_list'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "86b1f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url_col = df['main_image_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b41ce526",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://m.media-amazon.com/images/I/31S4tOQj4SL.jpg'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_url_col.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c5c64eb",
   "metadata": {},
   "source": [
    "# From Dylan: \n",
    "I worked on finding labels for the images since I think its going to be the strongest points. You guys can decide to use this notebook as a basis to further go deeper into the images. Do not alter this notebook as I may continue working on it. Create a new one adjacent to this one with your name.\n",
    "\n",
    "I decided to try to get these:\n",
    "- Clutter vs. Simplicity: segmentation models (detect background %), edge density, number of distinct color clusters.**DONE: ADDED TO DF**\n",
    "- Presence of Text: many low-quality sellers add text like “BEST DEAL” or “50% OFF.” Best sellers often don’t use text overlays on the main image. Tesseract, EasyOCR, label is has_text. **DONE: no text in images**\n",
    "- Composition & Focus: we will need AI for this and image detection. 1 object (main product) is usually better. Use object detection models (YOLO, Faster R-CNN) or just bounding-box heuristics. Might be unfeasible but worth trying.\n",
    "- Image Quality Basics: of cours:  sharpness / focus,  brightness / exposure, contrast, saturation / color vibrance, noise / compression artifacts.\n",
    "- Product Visibility: % of image covered by product. Cropped vs. fully visible. Overlapping/occluded? Maybe this is the ratio of product bounding box to total image.\n",
    "- Color and Aesthetic Features: Too many competing colors implies cluttered. Harmonious palette may be professional. Extract color histograms / clustering (k-means?)\n",
    "\n",
    "I decided to use ChatGPT for the image processing, specially color processing. If you're interested in learning more about it (because your career demands it), take your time to learn it properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80906317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/amazon-forecast/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os, io, asyncio, random, hashlib\n",
    "import aiohttp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "953fe832",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_AGENT = (\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) \"\n",
    "    \"AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0 Safari/537.36\"\n",
    ")\n",
    "\n",
    "def safe_name_from_url(url: str) -> str:\n",
    "    h = hashlib.md5(url.encode(\"utf-8\")).hexdigest()[:16]\n",
    "    base = url.split(\"/\")[-1].split(\"?\")[0]\n",
    "    ext = \".jpg\" if \".\" not in base else f\".{base.split('.')[-1]}\"\n",
    "    return f\"{h}{ext}\"\n",
    "\n",
    "async def fetch_one(session, url, save_dir, sem):\n",
    "    name = safe_name_from_url(url)\n",
    "    out_path = os.path.join(save_dir, name)\n",
    "    if os.path.exists(out_path):\n",
    "        return out_path\n",
    "\n",
    "    headers = {\"User-Agent\": USER_AGENT, \"Accept\": \"image/avif,image/webp,image/*,*/*;q=0.8\"}\n",
    "    async with sem:\n",
    "        for attempt in range(4):\n",
    "            try:\n",
    "                async with session.get(url, headers=headers, timeout=aiohttp.ClientTimeout(total=20)) as r:\n",
    "                    if r.status != 200:\n",
    "                        await asyncio.sleep(0.7 * (attempt + 1))\n",
    "                        continue\n",
    "                    data = await r.read()\n",
    "                    img = Image.open(io.BytesIO(data)).convert(\"RGB\")\n",
    "                    os.makedirs(save_dir, exist_ok=True)\n",
    "                    img.save(out_path, format=\"JPEG\", quality=95)\n",
    "                    return out_path\n",
    "            except Exception:\n",
    "                await asyncio.sleep(0.7 * (attempt + 1))\n",
    "        return None\n",
    "\n",
    "async def download_all(urls, save_dir=\"images_amz\", max_concurrency=8):\n",
    "    sem = asyncio.Semaphore(max_concurrency)\n",
    "    conn = aiohttp.TCPConnector(limit=0, ssl=False)\n",
    "    async with aiohttp.ClientSession(connector=conn) as session:\n",
    "        tasks = [fetch_one(session, u, save_dir, sem) for u in urls]\n",
    "        results = []\n",
    "        for f in tqdm(asyncio.as_completed(tasks), total=len(tasks), desc=\"Downloading\"):\n",
    "            results.append(await f)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a8a05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading:   0%|          | 0/17363 [00:00<?, ?it/s]/opt/anaconda3/envs/amazon-forecast/lib/python3.10/asyncio/tasks.py:270: RuntimeWarning: coroutine 'download_all' was never awaited\n",
      "  self.__wakeup, context=self._context)\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Downloading: 100%|██████████| 17363/17363 [13:02<00:00, 22.20it/s] \n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (17363) does not match length of index (17375)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m urls \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmain_image_url\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mdropna()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      5\u001b[0m paths \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mrun(download_all(urls, save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimages_amz\u001b[39m\u001b[38;5;124m\"\u001b[39m, max_concurrency\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m----> 6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_path\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m paths\n",
      "File \u001b[0;32m/opt/anaconda3/envs/amazon-forecast/lib/python3.10/site-packages/pandas/core/frame.py:4316\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4313\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   4314\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4315\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 4316\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/amazon-forecast/lib/python3.10/site-packages/pandas/core/frame.py:4529\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4519\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4520\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4521\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4522\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4527\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4528\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4529\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4531\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4532\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4533\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4534\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[1;32m   4535\u001b[0m     ):\n\u001b[1;32m   4536\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4537\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/anaconda3/envs/amazon-forecast/lib/python3.10/site-packages/pandas/core/frame.py:5273\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   5270\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m   5272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 5273\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5274\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   5275\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   5276\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[1;32m   5277\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5280\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[1;32m   5281\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/amazon-forecast/lib/python3.10/site-packages/pandas/core/common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[0;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    578\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (17363) does not match length of index (17375)"
     ]
    }
   ],
   "source": [
    "import nest_asyncio, asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "urls = df[\"main_image_url\"].dropna().tolist()\n",
    "paths = asyncio.run(download_all(urls, save_dir=\"images_amz\", max_concurrency=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e10d8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, hashlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def expected_path_from_url(url, save_dir=\"images_amz\"):\n",
    "    if pd.isna(url):\n",
    "        return np.nan\n",
    "    base = url.split(\"/\")[-1].split(\"?\")[0]\n",
    "    ext = \".jpg\" if \".\" not in base else f\".{base.split('.')[-1]}\"\n",
    "    name = hashlib.md5(url.encode(\"utf-8\")).hexdigest()[:16] + ext\n",
    "    path = os.path.join(save_dir, name)\n",
    "    return path if os.path.exists(path) else np.nan\n",
    "\n",
    "df[\"image_path\"] = df[\"main_image_url\"].apply(expected_path_from_url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c577e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, cv2, pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def load_cv2(path):\n",
    "    data = np.fromfile(path, dtype=np.uint8)\n",
    "    return cv2.imdecode(data, cv2.IMREAD_COLOR) # BGR uint8\n",
    "\n",
    "def edge_density(img_bgr, low=100, high=200):\n",
    "    if img_bgr is None: return np.nan\n",
    "    gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    h, w = gray.shape[:2]\n",
    "    edges = cv2.Canny(gray, threshold1=low, threshold2=high)\n",
    "    return float(np.count_nonzero(edges)) / float(h*w + 1e-9)\n",
    "\n",
    "def background_fractions(img_bgr):\n",
    "    if img_bgr is None:\n",
    "        return dict(bg_white_pct=np.nan, bg_neutral_pct=np.nan)\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    H,S,V = cv2.split(hsv)\n",
    "    Sf, Vf = S.astype(np.float32)/255.0, V.astype(np.float32)/255.0\n",
    "    white_mask   = (Vf > 0.95) & (Sf < 0.10) # bright and low saturation\n",
    "    neutral_mask = (Sf < 0.12) # low saturation = neutral bg\n",
    "    return dict(\n",
    "        bg_white_pct=float(np.mean(white_mask)),\n",
    "        bg_neutral_pct=float(np.mean(neutral_mask)),\n",
    "    )\n",
    "\n",
    "def palette_complexity(img_bgr, K=5, sample_px=64*64, significant=0.05):\n",
    "    if img_bgr is None:\n",
    "        return dict(n_clusters_sig=np.nan, color_entropy=np.nan, largest_cluster_pct=np.nan)\n",
    "\n",
    "    h, w = img_bgr.shape[:2]\n",
    "    scale = max(1, int(np.sqrt((h*w)/sample_px)))\n",
    "    small = cv2.resize(img_bgr, (w//scale, h//scale), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    lab = cv2.cvtColor(small, cv2.COLOR_BGR2LAB).reshape(-1, 3).astype(np.float32)\n",
    "    km = KMeans(n_clusters=K, n_init=5, random_state=42)\n",
    "    labels = km.fit_predict(lab)\n",
    "    counts = np.bincount(labels, minlength=K).astype(np.float32)\n",
    "    weights = counts / counts.sum()\n",
    "\n",
    "    n_clusters_sig = int(np.sum(weights >= significant))\n",
    "    eps = 1e-12\n",
    "    color_entropy = -np.sum(weights * np.log(weights + eps)) / np.log(K + eps)  # normalized [0,1]\n",
    "    largest_cluster_pct = float(weights.max())\n",
    "\n",
    "    return dict(\n",
    "        n_clusters_sig=n_clusters_sig,\n",
    "        color_entropy=float(color_entropy),\n",
    "        largest_cluster_pct=largest_cluster_pct\n",
    "    )\n",
    "\n",
    "def clutter_features_for_path(path):\n",
    "    try:\n",
    "        img = load_cv2(path)\n",
    "        ed = edge_density(img)\n",
    "        bg = background_fractions(img)\n",
    "        pal = palette_complexity(img, K=5)\n",
    "        return dict(\n",
    "            image_path=path,\n",
    "            edge_density=ed,\n",
    "            bg_white_pct=bg[\"bg_white_pct\"],\n",
    "            bg_neutral_pct=bg[\"bg_neutral_pct\"],\n",
    "            n_clusters_sig=pal[\"n_clusters_sig\"],\n",
    "            color_entropy=pal[\"color_entropy\"],\n",
    "            largest_cluster_pct=pal[\"largest_cluster_pct\"],\n",
    "        )\n",
    "    except Exception:\n",
    "        return dict(\n",
    "            image_path=path,\n",
    "            edge_density=np.nan,\n",
    "            bg_white_pct=np.nan,\n",
    "            bg_neutral_pct=np.nan,\n",
    "            n_clusters_sig=np.nan,\n",
    "            color_entropy=np.nan,\n",
    "            largest_cluster_pct=np.nan,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "771a6ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clutter features: 100%|██████████| 17334/17334 [10:50<00:00, 26.63it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "have = df[\"image_path\"].notna()\n",
    "feat_rows = [clutter_features_for_path(p) for p in tqdm(df.loc[have, \"image_path\"], desc=\"Clutter features\")]\n",
    "df_feats = pd.DataFrame(feat_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d9ae4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"edge_density\",\"n_clusters_sig\",\"color_entropy\",\"bg_white_pct\",\"bg_neutral_pct\",\"largest_cluster_pct\"]:\n",
    "    m = df_feats[col].mean()\n",
    "    s = df_feats[col].std(ddof=0) + 1e-9 #small number so we dont divide by 0 in some cases.\n",
    "    df_feats[col+\"_z\"] = (df_feats[col] - m)/s #this is the zscore (stats)\n",
    "\n",
    "df_feats[\"clutter_score\"] = ( #higher = more clutter\n",
    "    + 0.45 * df_feats[\"edge_density_z\"]\n",
    "    + 0.30 * df_feats[\"n_clusters_sig_z\"]\n",
    "    + 0.25 * df_feats[\"color_entropy_z\"]\n",
    "    - 0.30 * df_feats[\"bg_white_pct_z\"]\n",
    "    - 0.20 * df_feats[\"bg_neutral_pct_z\"]\n",
    "    - 0.15 * df_feats[\"largest_cluster_pct_z\"]\n",
    ")\n",
    "\n",
    "df_model = df.merge(df_feats, on=\"image_path\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c4926fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>clutter_score</th>\n",
       "      <th>bg_white_pct</th>\n",
       "      <th>largest_cluster_pct</th>\n",
       "      <th>edge_density</th>\n",
       "      <th>n_clusters_sig</th>\n",
       "      <th>color_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>images_amz/866237e84fde8a3c.jpg</td>\n",
       "      <td>-3.652532</td>\n",
       "      <td>0.961232</td>\n",
       "      <td>0.950769</td>\n",
       "      <td>0.001007</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10264</th>\n",
       "      <td>images_amz/eb58f783c164e724.jpg</td>\n",
       "      <td>-3.601807</td>\n",
       "      <td>0.954870</td>\n",
       "      <td>0.943848</td>\n",
       "      <td>0.001227</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.173692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9455</th>\n",
       "      <td>images_amz/0e6a40ff8d3a326e.jpg</td>\n",
       "      <td>-3.591841</td>\n",
       "      <td>0.955214</td>\n",
       "      <td>0.947998</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.169502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9595</th>\n",
       "      <td>images_amz/45c033bc7162de66.jpg</td>\n",
       "      <td>-3.585157</td>\n",
       "      <td>0.955205</td>\n",
       "      <td>0.946777</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.174915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9376</th>\n",
       "      <td>images_amz/96e730aaf104e216.jpg</td>\n",
       "      <td>-3.567192</td>\n",
       "      <td>0.954709</td>\n",
       "      <td>0.941895</td>\n",
       "      <td>0.002303</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.185530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_path  clutter_score  bg_white_pct  \\\n",
       "11381  images_amz/866237e84fde8a3c.jpg      -3.652532      0.961232   \n",
       "10264  images_amz/eb58f783c164e724.jpg      -3.601807      0.954870   \n",
       "9455   images_amz/0e6a40ff8d3a326e.jpg      -3.591841      0.955214   \n",
       "9595   images_amz/45c033bc7162de66.jpg      -3.585157      0.955205   \n",
       "9376   images_amz/96e730aaf104e216.jpg      -3.567192      0.954709   \n",
       "\n",
       "       largest_cluster_pct  edge_density  n_clusters_sig  color_entropy  \n",
       "11381             0.950769      0.001007             1.0       0.152908  \n",
       "10264             0.943848      0.001227             1.0       0.173692  \n",
       "9455              0.947998      0.002823             1.0       0.169502  \n",
       "9595              0.946777      0.002446             1.0       0.174915  \n",
       "9376              0.941895      0.002303             1.0       0.185530  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>clutter_score</th>\n",
       "      <th>bg_white_pct</th>\n",
       "      <th>largest_cluster_pct</th>\n",
       "      <th>edge_density</th>\n",
       "      <th>n_clusters_sig</th>\n",
       "      <th>color_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8158</th>\n",
       "      <td>images_amz/df1a7d5e92f416a2.jpg</td>\n",
       "      <td>4.772736</td>\n",
       "      <td>0.020349</td>\n",
       "      <td>0.248663</td>\n",
       "      <td>0.240882</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.966516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16981</th>\n",
       "      <td>images_amz/9ce546164ec235be.jpg</td>\n",
       "      <td>4.705153</td>\n",
       "      <td>0.132536</td>\n",
       "      <td>0.296201</td>\n",
       "      <td>0.254964</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.942215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>images_amz/1edd23725c057b44.jpg</td>\n",
       "      <td>4.670320</td>\n",
       "      <td>0.051152</td>\n",
       "      <td>0.335786</td>\n",
       "      <td>0.241129</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.951495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6208</th>\n",
       "      <td>images_amz/c9c9f4849d181e55.jpg</td>\n",
       "      <td>4.667717</td>\n",
       "      <td>0.109912</td>\n",
       "      <td>0.232692</td>\n",
       "      <td>0.241584</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.996853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17694</th>\n",
       "      <td>images_amz/b922bd22bca88a1c.jpg</td>\n",
       "      <td>4.622601</td>\n",
       "      <td>0.125244</td>\n",
       "      <td>0.301441</td>\n",
       "      <td>0.249596</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.955061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            image_path  clutter_score  bg_white_pct  \\\n",
       "8158   images_amz/df1a7d5e92f416a2.jpg       4.772736      0.020349   \n",
       "16981  images_amz/9ce546164ec235be.jpg       4.705153      0.132536   \n",
       "6601   images_amz/1edd23725c057b44.jpg       4.670320      0.051152   \n",
       "6208   images_amz/c9c9f4849d181e55.jpg       4.667717      0.109912   \n",
       "17694  images_amz/b922bd22bca88a1c.jpg       4.622601      0.125244   \n",
       "\n",
       "       largest_cluster_pct  edge_density  n_clusters_sig  color_entropy  \n",
       "8158              0.248663      0.240882             5.0       0.966516  \n",
       "16981             0.296201      0.254964             5.0       0.942215  \n",
       "6601              0.335786      0.241129             5.0       0.951495  \n",
       "6208              0.232692      0.241584             5.0       0.996853  \n",
       "17694             0.301441      0.249596             5.0       0.955061  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "simple = df_model.sort_values(\"clutter_score\", ascending=True).head(5)\n",
    "busy   = df_model.sort_values(\"clutter_score\", ascending=False).head(5)\n",
    "\n",
    "cols = [\"image_path\",\"clutter_score\",\"bg_white_pct\",\"largest_cluster_pct\",\"edge_density\",\"n_clusters_sig\",\"color_entropy\"]\n",
    "display(simple[cols])\n",
    "display(busy[cols])\n",
    "\n",
    "df_model.to_csv(\"df_with_clutter_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1fd764ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "image_count             -0.063141\n",
       "review_count                  NaN\n",
       "avg_rating                    NaN\n",
       "bsr_best                 1.000000\n",
       "units_per_month               NaN\n",
       "sales_velocity_daily          NaN\n",
       "edge_density            -0.002961\n",
       "bg_white_pct            -0.022585\n",
       "bg_neutral_pct          -0.029610\n",
       "n_clusters_sig           0.002489\n",
       "color_entropy            0.000001\n",
       "largest_cluster_pct     -0.004283\n",
       "edge_density_z          -0.002961\n",
       "n_clusters_sig_z         0.002489\n",
       "color_entropy_z          0.000001\n",
       "bg_white_pct_z          -0.022585\n",
       "bg_neutral_pct_z        -0.029610\n",
       "largest_cluster_pct_z   -0.004283\n",
       "clutter_score            0.009661\n",
       "Name: bsr_best, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_model.select_dtypes(np.number).corr()['bsr_best']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079a4dae",
   "metadata": {},
   "source": [
    "I went thru the images. None have text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a3e2b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (amazon-forecast)",
   "language": "python",
   "name": "amazon-forecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
